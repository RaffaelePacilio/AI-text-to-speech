{
    "sourceFile": "src/app/form/page.tsx",
    "activeCommit": 0,
    "commits": [
        {
            "activePatchIndex": 0,
            "patches": [
                {
                    "date": 1732786411860,
                    "content": "Index: \n===================================================================\n--- \n+++ \n"
                }
            ],
            "date": 1732786411860,
            "name": "Commit-0",
            "content": "'use client'\n\nimport { useState, useEffect, useRef } from 'react';\nimport { Subject } from 'rxjs';\nimport { debounceTime, distinctUntilChanged, map } from 'rxjs/operators';\n\nconst VoiceInputForm = () => {\n  const [transcript, setTranscript] = useState(''); \n  const [isListening, setIsListening] = useState(false); \n  const [error, setError] = useState(null);\n  const [response, setResponse] = useState<string | null>(null); // Stato per la risposta del server\n  const timeoutRef = useRef<NodeJS.Timeout | null>(null);\n  const recognitionTimeout = 5000;\n\n  const speechSubject = useRef(new Subject<string>());\n  const [recognition, setRecognition] = useState<any>(null); // Stato per riconoscimento vocale\n\n  // Gestisci la risposta dal server\n  const sendToServer = async () => {\n    try {\n      const response = await fetch('/api', {\n        method: 'POST',\n        headers: {\n          'Content-Type': 'application/json',\n        },\n        body: JSON.stringify({text: transcript}),\n      });\n\n      const data = await response.json();\n      console.log('Risposta del server:', data); // Stampa la risposta del server\n      setResponse(data.reply); // Imposta la risposta ricevuta nel state\n    } catch (error) {\n      console.error('Errore nell\\'invio del testo:', error);\n    }\n  };\n\n  // Funzione che gestisce i risultati del riconoscimento vocale\n  const handleRecognitionResult = (event: any) => {\n    const currentTranscript = event.results[event.resultIndex][0].transcript;\n    speechSubject.current.next(currentTranscript);\n    resetTimeout();\n  };\n\n  // Funzione che avvia il riconoscimento vocale\n  const startListening = () => {\n    recognition?.start();\n    setIsListening(true); \n    setError(null); \n    setTranscript(''); \n    resetTimeout(); \n  };\n\n  // Funzione che ferma il riconoscimento vocale\n  const stopListening = () => {\n    recognition?.stop(); \n    setIsListening(false);\n    if (timeoutRef.current) {\n      clearTimeout(timeoutRef.current); \n    }\n  };\n\n  // Funzione che avvia il timeout di 5 secondi\n  const startTimeout = () => {\n    timeoutRef.current = setTimeout(() => {\n      console.log(\"Nessun parlato per 5 secondi, fermo il microfono\");\n      stopListening(); \n    }, recognitionTimeout);\n  };\n\n  // Funzione che resetta il timeout\n  const resetTimeout = () => {\n    if (timeoutRef.current) {\n      clearTimeout(timeoutRef.current); \n    }\n    startTimeout(); \n  };\n\n  // Gestire la trascrizione con RxJS\n  useEffect(() => {\n    const subscription = speechSubject.current.pipe(\n      debounceTime(2000), \n      distinctUntilChanged(),\n      map((newTranscript: string) => newTranscript.trim()) \n    ).subscribe((newTranscript) => {\n      setTranscript((prevTranscript) => {\n        if (prevTranscript.endsWith(newTranscript)) {\n          return prevTranscript;\n        }\n        return prevTranscript + ' ' + newTranscript;\n      });\n    });\n\n    return () => {\n      subscription.unsubscribe();\n    };\n  }, []);\n\n  // Crea il riconoscimento vocale solo nel client\n  useEffect(() => {\n    if (typeof window !== 'undefined') {\n      const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;\n      if (SpeechRecognition) {\n        const recognitionInstance = new SpeechRecognition();\n        recognitionInstance.lang = 'it-IT'; \n        recognitionInstance.interimResults = true;\n        recognitionInstance.continuous = true;\n        recognitionInstance.maxAlternatives = 1;\n        recognitionInstance.onresult = handleRecognitionResult;\n        setRecognition(recognitionInstance);\n      }\n    }\n  }, []);\n\n  // Cleanup al momento dello smontaggio\n  useEffect(() => {\n    return () => {\n      if (timeoutRef.current) {\n        clearTimeout(timeoutRef.current); \n      }\n      recognition?.abort(); \n    };\n  }, [recognition]);\n\n  return (\n    <div>\n      <h1>Input tramite voce</h1>\n      <form>\n        <label htmlFor=\"voiceInput\">Inserisci testo tramite voce</label>\n        <textarea\n          className='text-area'\n          id=\"voiceInput\"\n          value={transcript} \n          onChange={(e) => setTranscript(e.target.value)} \n          placeholder=\"Parla per scrivere...\"\n        />\n      </form>\n      <div>\n        {isListening ? (\n          <div>...registra...</div>\n        ) : (\n          <button onClick={startListening}>Inizia a parlare</button>\n        )}\n      </div>\n      <div>\n        <button onClick={sendToServer}>Invia al server</button>\n      </div>\n      {error && <p style={{ color: 'red' }}>Errore: {error}</p>}\n      {response && <p>Risposta dal server: {response}</p>}\n    </div>\n  );\n};\n\nexport default VoiceInputForm;\n"
        }
    ]
}